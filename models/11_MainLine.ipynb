{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Python version: 3.9.2 (tags/v3.9.2:1a79785, Feb 19 2021, 13:44:55) [MSC v.1928 64 bit (AMD64)]\n",
      "pandas version: 1.3.2\n",
      "matplotlib version: 3.4.3\n",
      "NumPy version: 1.22.4\n",
      "scikit-learn version: 0.24.2\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Sytem\n",
    "import sys,os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "import random\n",
    "import IPython\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Visualidation\n",
    "import sweetviz as sv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "#EDA\n",
    "import sweetviz as sv\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "#model\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV,GridSearchCV,StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from skopt import BayesSearchCV\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('-'*40)\n",
    "\n",
    "print(\"Python version: {}\". format(sys.version))\n",
    "\n",
    "print(\"pandas version: {}\". format(pd.__version__))\n",
    "\n",
    "print(\"matplotlib version: {}\". format(matplotlib.__version__))\n",
    "\n",
    "print(\"NumPy version: {}\". format(np.__version__))\n",
    "\n",
    "\n",
    "print(\"scikit-learn version: {}\". format(sklearn.__version__))\n",
    "print('-'*40)\n",
    "Target = \"Perished\"\n",
    "PATH_LOG = \"./log.csv\"\n",
    "PATH_df = \"./df\"\n",
    "ID = 11\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Shape of Train Data\n",
      "[row :891,column :12]\n",
      "-------------------------\n",
      "Shape of Test Data\n",
      "[row :418,column :12]\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/input/train_alpha.csv')\n",
    "df_test = pd.read_csv('../data/input/test_alpha.csv')\n",
    "sample = pd.read_csv('../data/input/gender_submission.csv')\n",
    "data = pd.concat([df_train,df_test],sort=False)\n",
    "print('-'*25)\n",
    "print(\"Shape of Train Data\\n[row :{},column :{}]\".format(\n",
    "    df_train.shape[0], df_train.shape[1]))\n",
    "print('-'*25)\n",
    "print(\"Shape of Test Data\\n[row :{},column :{}]\".format(\n",
    "    df_test.shape[0], df_test.shape[1]))\n",
    "print('-'*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "ohe = OneHotEncoder()\n",
    "data['Title'] = data['Name'].str.split(\n",
    "        \", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "\n",
    "title_names = (data.Title.value_counts() < 10)\n",
    "data[\"Title\"] = data[\"Title\"].apply(lambda x: \"other\" if title_names.loc[x] == True else x)\n",
    "faremean = data.Fare.mean()\n",
    "data[\"Fare\"].fillna(faremean,inplace=True)\n",
    "data['FareBin'] = pd.qcut(data['Fare'], 10)\n",
    "data['Fare_Code'] = label.fit_transform(data['FareBin'])\n",
    "N_Age_Code = 3\n",
    "data.replace({'Sex':{'male':0,'female':1}},inplace=True)\n",
    "data['Age_Code'] = label.fit_transform(pd.qcut(data['Age'], N_Age_Code))\n",
    "data['Embarked_Code'] = label.fit_transform(data['Embarked'])\n",
    "data[\"Embarked\"].fillna('S',inplace=True)\n",
    "embarked_ohe = pd.get_dummies(data.Embarked)\n",
    "data = pd.concat([data, embarked_ohe], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Perished', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Title', 'FareBin',\n",
       "       'Fare_Code', 'Age_Code', 'Embarked_Code', 'C', 'Q', 'S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = [\"Name\",\"Ticket\",\"Cabin\",\"Embarked\",\"Title\",'FareBin',\"Fare_Code\",'C','Q','S']\n",
    "dataset = data.drop(columns=drop_columns)\n",
    "train = dataset[:len(df_train)]\n",
    "test = dataset[len(df_train):]\n",
    "testIds = test['PassengerId'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:, 2:].values\n",
    "y_train = train.iloc[:, 1].values\n",
    "X_test = test.iloc[:, 2:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "各1層目モデルに対する操作（定義・訓練・予測）を簡略化するため、分類器の拡張クラスを定義します。\n",
    "\"\"\"\n",
    "class ClfBuilder(object):\n",
    "    def __init__(self, clf, params=None):\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "\"\"\"\n",
    "スタッキングでは2層目のモデルに1層目のモデルの予測値を利用します。2層目で既知のデータに対する過学習を防ぐため、1層目でOut-of-Foldによる予測値を算出してこれを2層目の学習に利用します。以下の実装では、StratifiedKFoldで5分割の交差検証を行っています。\n",
    "\"\"\"\n",
    "def get_base_model_preds(clf, X_train, y_train, X_test):\n",
    "    print(clf.clf)\n",
    "\n",
    "    N_SPLITS = 5\n",
    "    oof_valid = np.zeros((X_train.shape[0], NUM_CLASSES))\n",
    "    oof_test = np.zeros((X_test.shape[0], NUM_CLASSES))\n",
    "    oof_test_skf = np.zeros((N_SPLITS, X_test.shape[0], NUM_CLASSES))\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS)\n",
    "    for i, (train_index, valid_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        print('[CV] {}/{}'.format(i+1, N_SPLITS))\n",
    "        X_train_, X_valid_ = X_train[train_index], X_train[valid_index]\n",
    "        y_train_, y_valid_ = y_train[train_index], y_train[valid_index]\n",
    "\n",
    "        clf.fit(X_train_, y_train_)\n",
    "\n",
    "        oof_valid[valid_index] = clf.predict_proba(X_valid_)\n",
    "        oof_test_skf[i, :] = clf.predict_proba(X_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_valid, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_params = {\n",
    "    'n_estimators': 100, \n",
    "    'max_depth': 10, \n",
    "    'random_state': 0, \n",
    "}\n",
    "gbc_params = {\n",
    "    'n_estimators': 50, \n",
    "    'max_depth': 10, \n",
    "    'random_state': 0, \n",
    "}\n",
    "etc_params = {\n",
    "    'n_estimators': 100, \n",
    "    'max_depth': 10,\n",
    "    'random_state': 0, \n",
    "}\n",
    "xgbc1_params = {\n",
    "    'n_estimators': 100, \n",
    "    'max_depth': 10,\n",
    "    'random_state': 0, \n",
    "}\n",
    "knn1_params = {'n_neighbors': 4}\n",
    "knn2_params = {'n_neighbors': 8}\n",
    "knn3_params = {'n_neighbors': 16}\n",
    "knn4_params = {'n_neighbors': 32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = ClfBuilder(clf=RandomForestClassifier, params=rfc_params)\n",
    "gbc = ClfBuilder(clf=GradientBoostingClassifier, params=gbc_params)\n",
    "etc = ClfBuilder(clf=ExtraTreesClassifier, params=etc_params)\n",
    "xgbc1 = ClfBuilder(clf=XGBClassifier, params=xgbc1_params)\n",
    "knn1 = ClfBuilder(clf=KNeighborsClassifier, params=knn1_params)\n",
    "knn2 = ClfBuilder(clf=KNeighborsClassifier, params=knn2_params)\n",
    "knn3 = ClfBuilder(clf=KNeighborsClassifier, params=knn3_params)\n",
    "knn4 = ClfBuilder(clf=KNeighborsClassifier, params=knn4_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=10, random_state=0)\n",
      "[CV] 1/5\n",
      "[CV] 2/5\n",
      "[CV] 3/5\n",
      "[CV] 4/5\n",
      "[CV] 5/5\n",
      "GradientBoostingClassifier(max_depth=10, n_estimators=50, random_state=0)\n",
      "[CV] 1/5\n",
      "[CV] 2/5\n",
      "[CV] 3/5\n",
      "[CV] 4/5\n",
      "[CV] 5/5\n",
      "ExtraTreesClassifier(max_depth=10, random_state=0)\n",
      "[CV] 1/5\n",
      "[CV] 2/5\n",
      "[CV] 3/5\n",
      "[CV] 4/5\n",
      "[CV] 5/5\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...)\n",
      "[CV] 1/5\n",
      "[CV] 2/5\n",
      "[CV] 3/5\n",
      "[CV] 4/5\n",
      "[CV] 5/5\n",
      "KNeighborsClassifier(n_neighbors=4)\n",
      "[CV] 1/5\n",
      "[CV] 2/5\n",
      "[CV] 3/5\n",
      "[CV] 4/5\n",
      "[CV] 5/5\n",
      "KNeighborsClassifier(n_neighbors=8)\n",
      "[CV] 1/5\n",
      "[CV] 2/5\n",
      "[CV] 3/5\n",
      "[CV] 4/5\n",
      "[CV] 5/5\n",
      "KNeighborsClassifier(n_neighbors=16)\n",
      "[CV] 1/5\n",
      "[CV] 2/5\n",
      "[CV] 3/5\n",
      "[CV] 4/5\n",
      "[CV] 5/5\n",
      "KNeighborsClassifier(n_neighbors=32)\n",
      "[CV] 1/5\n",
      "[CV] 2/5\n",
      "[CV] 3/5\n",
      "[CV] 4/5\n",
      "[CV] 5/5\n"
     ]
    }
   ],
   "source": [
    "oof_valid_rfc, oof_test_rfc = get_base_model_preds(rfc, X_train, y_train, X_test)\n",
    "oof_valid_gbc, oof_test_gbc = get_base_model_preds(gbc, X_train, y_train, X_test)\n",
    "oof_valid_etc, oof_test_etc = get_base_model_preds(etc, X_train, y_train, X_test)\n",
    "oof_valid_xgbc1, oof_test_xgbc1 = get_base_model_preds(xgbc1, X_train, y_train, X_test)\n",
    "oof_valid_knn1, oof_test_knn1 = get_base_model_preds(knn1, X_train, y_train, X_test)\n",
    "oof_valid_knn2, oof_test_knn2 = get_base_model_preds(knn2, X_train, y_train, X_test)\n",
    "oof_valid_knn3, oof_test_knn3 = get_base_model_preds(knn3, X_train, y_train, X_test)\n",
    "oof_valid_knn4, oof_test_knn4 = get_base_model_preds(knn4, X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_base = np.concatenate([oof_valid_rfc, \n",
    "                               oof_valid_gbc, \n",
    "                               oof_valid_etc, \n",
    "                               oof_valid_xgbc1, \n",
    "                               oof_valid_knn1, \n",
    "                               oof_valid_knn2, \n",
    "                               oof_valid_knn3, \n",
    "                               oof_valid_knn4, \n",
    "                              ], axis=1)\n",
    "X_test_base = np.concatenate([oof_test_rfc, \n",
    "                              oof_test_gbc, \n",
    "                              oof_test_etc, \n",
    "                              oof_test_xgbc1, \n",
    "                              oof_test_knn1, \n",
    "                              oof_test_knn2, \n",
    "                              oof_test_knn3, \n",
    "                              oof_test_knn4, \n",
    "                             ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc2_params = {\n",
    "    'n_eetimators': 100, \n",
    "    'max_depth': 5, \n",
    "    'random_state': 42, \n",
    "}\n",
    "xgbc2 = XGBClassifier(**xgbc2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:38:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_eetimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_eetimators=100,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=42, reg_alpha=0, ...)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc2.fit(X_train_base, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = xgbc2.predict(X_test_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/output/11_submission_ensemble.csv\n",
      "Submission Format:(418, 2) \n",
      "My Sumbisison Format:(418, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Perished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Perished\n",
       "0          892         1\n",
       "1          893         1\n",
       "2          894         1\n",
       "3          895         1\n",
       "4          896         0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_sub =  \"../data/output/\"+str(ID)+\"_submission_\"+\"ensemble\"+\".csv\"\n",
    "print(PATH_sub)\n",
    "submission_df = pd.DataFrame(columns=['PassengerId', Target])\n",
    "submission_df['PassengerId'] = df_test['PassengerId']\n",
    "submission_df[Target] = prediction\n",
    "submission_df.reset_index(drop=True, inplace=True)\n",
    "submission_df.to_csv(PATH_sub, header=True, index=False)\n",
    "print(\"Submission Format:{} \".format(sample.shape))\n",
    "print(\"My Sumbisison Format:{}\".format(submission_df.shape))\n",
    "submission_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "68ea084522a32e1c5efebe8e26724b4feaefc93bc2807a5a214dcc5b0260bfd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
