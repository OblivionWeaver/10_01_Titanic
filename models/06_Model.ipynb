{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.2 (tags/v3.9.2:1a79785, Feb 19 2021, 13:44:55) [MSC v.1928 64 bit (AMD64)]\n",
      "pandas version: 1.3.2\n",
      "matplotlib version: 3.4.3\n",
      "NumPy version: 1.20.1\n",
      "SciPy version: 1.7.1\n",
      "IPython version: 7.26.0\n",
      "scikit-learn version: 0.24.2\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "#load packages\n",
    "import sys #access to system parameters https://docs.python.org/3/library/sys.html\n",
    "print(\"Python version: {}\". format(sys.version))\n",
    "\n",
    "import pandas as pd #collection of functions for data processing and analysis modeled after R dataframes with SQL like features\n",
    "from pandas import Series, DataFrame\n",
    "print(\"pandas version: {}\". format(pd.__version__))\n",
    "\n",
    "import matplotlib #collection of functions for scientific and publication-ready visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "print(\"matplotlib version: {}\". format(matplotlib.__version__))\n",
    "\n",
    "import numpy as np #foundational package for scientific computing\n",
    "print(\"NumPy version: {}\". format(np.__version__))\n",
    "\n",
    "import scipy as sp #collection of functions for scientific computing and advance mathematics\n",
    "print(\"SciPy version: {}\". format(sp.__version__)) \n",
    "\n",
    "import IPython\n",
    "from IPython import display #pretty printing of dataframes in Jupyter notebook\n",
    "print(\"IPython version: {}\". format(IPython.__version__)) \n",
    "\n",
    "import sklearn #collection of machine learning algorithms\n",
    "print(\"scikit-learn version: {}\". format(sklearn.__version__))\n",
    "\n",
    "#misc libraries\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('-'*25)\n",
    "# データインポートライブラリ\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import warnings\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import re as re\n",
    "import string\n",
    "\n",
    "# データ加工・処理・分析ライブラリ\n",
    "import scipy as sp\n",
    "import sweetviz as sv\n",
    "\n",
    "\n",
    "# 可視化ライブラリ\n",
    "from pandas_profiling import ProfileReport\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#Model\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "%precision 3\n",
    "\n",
    "\n",
    "SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df(train_data, test_data, sort=True, drop=True):\n",
    "    \"\"\"\n",
    "    overview\n",
    "    >return a  concatenated df of training and test data\n",
    "    needed\n",
    "    >pandas as pd\n",
    "    input\n",
    "    >train_data{DataFrame}:train_data\n",
    "    >test_data{DataFrame}:test_data\n",
    "    >sort{bool}:True or False\n",
    "    \"\"\"\n",
    "    return pd.concat([train_data, test_data], sort=sort).reset_index(drop=drop)\n",
    "\n",
    "\n",
    "def divide_df(all_data, target, len=890):\n",
    "    \"\"\"\n",
    "    overview\n",
    "    > Returns divided dfs of training and test set\n",
    "    needed\n",
    "    >\n",
    "    input\n",
    "    > all_data{DataFrame}:Train+Test\n",
    "    > target{str} :Target columns\n",
    "    > len(int):len of train_data\n",
    "    \n",
    "    \"\"\"\n",
    "    return all_data.loc[:len], all_data.loc[len:].drop([target], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 44)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./df/EDA_05_train.csv\")\n",
    "df_test = pd.read_csv(\"./df/EDA_05_test.csv\")\n",
    "Target = 'Survived'\n",
    "Final_target = 'Perished'\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Deck_1</th>\n",
       "      <th>Deck_2</th>\n",
       "      <th>Deck_3</th>\n",
       "      <th>Deck_4</th>\n",
       "      <th>Embarked_1</th>\n",
       "      <th>Embarked_2</th>\n",
       "      <th>Embarked_3</th>\n",
       "      <th>Family_Size_Grouped_1</th>\n",
       "      <th>Family_Size_Grouped_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_1</th>\n",
       "      <th>Sex_2</th>\n",
       "      <th>Survival_Rate</th>\n",
       "      <th>Survival_Rate_NA</th>\n",
       "      <th>Ticket_Frequency</th>\n",
       "      <th>Title_1</th>\n",
       "      <th>Title_2</th>\n",
       "      <th>Title_3</th>\n",
       "      <th>Title_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Deck_1  Deck_2  Deck_3  Deck_4  Embarked_1  Embarked_2  Embarked_3  \\\n",
       "0    2     0.0     0.0     0.0     1.0         0.0         0.0         1.0   \n",
       "1    7     1.0     0.0     0.0     0.0         1.0         0.0         0.0   \n",
       "2    4     0.0     0.0     0.0     1.0         0.0         0.0         1.0   \n",
       "3    7     1.0     0.0     0.0     0.0         0.0         0.0         1.0   \n",
       "4    7     0.0     0.0     0.0     1.0         0.0         0.0         1.0   \n",
       "\n",
       "   Family_Size_Grouped_1  Family_Size_Grouped_2  ...  Pclass_3  Sex_1  Sex_2  \\\n",
       "0                    0.0                    0.0  ...       1.0    0.0    1.0   \n",
       "1                    0.0                    0.0  ...       0.0    1.0    0.0   \n",
       "2                    1.0                    0.0  ...       1.0    1.0    0.0   \n",
       "3                    0.0                    0.0  ...       0.0    1.0    0.0   \n",
       "4                    1.0                    0.0  ...       1.0    0.0    1.0   \n",
       "\n",
       "   Survival_Rate  Survival_Rate_NA  Ticket_Frequency  Title_1  Title_2  \\\n",
       "0       0.383838               0.0                 1      0.0      0.0   \n",
       "1       1.000000               1.0                 2      0.0      0.0   \n",
       "2       0.383838               0.0                 1      0.0      0.0   \n",
       "3       0.383838               0.0                 2      0.0      0.0   \n",
       "4       0.383838               0.0                 1      0.0      0.0   \n",
       "\n",
       "   Title_3  Title_4  \n",
       "0      0.0      1.0  \n",
       "1      1.0      0.0  \n",
       "2      1.0      0.0  \n",
       "3      1.0      0.0  \n",
       "4      0.0      1.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = concat_df(df_train, df_test)\n",
    "drop_cols = ['Deck', 'Embarked', 'Family', 'Family_Size', 'Family_Size_Grouped', Target,\n",
    "             'Name', 'Parch', 'PassengerId', 'Pclass', 'Sex', 'SibSp', 'Ticket', 'Title',\n",
    "             'Ticket_Survival_Rate', 'Family_Survival_Rate', 'Ticket_Survival_Rate_NA', 'Family_Survival_Rate_NA']\n",
    "\n",
    "df_all.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (891, 26)\n",
      "y_train shape: (891,)\n",
      "X_test shape: (418, 26)\n"
     ]
    }
   ],
   "source": [
    "X_train = StandardScaler().fit_transform(df_train.drop(columns=drop_cols))\n",
    "y_train = df_train[Target].values\n",
    "X_test = StandardScaler().fit_transform(df_test.drop(columns=drop_cols))\n",
    "\n",
    "print('X_train shape: {}'.format(X_train.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "print('X_test shape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy 3*STD</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>{'covariance_estimator': None, 'n_components':...</td>\n",
       "      <td>0.855993</td>\n",
       "      <td>0.853358</td>\n",
       "      <td>0.047241</td>\n",
       "      <td>0.007823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>{'alphas': array([ 0.1,  1. , 10. ]), 'class_w...</td>\n",
       "      <td>0.855805</td>\n",
       "      <td>0.852985</td>\n",
       "      <td>0.052552</td>\n",
       "      <td>0.009171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>0.915543</td>\n",
       "      <td>0.852239</td>\n",
       "      <td>0.060531</td>\n",
       "      <td>0.106151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>{'Cs': 10, 'class_weight': None, 'cv': None, '...</td>\n",
       "      <td>0.861049</td>\n",
       "      <td>0.850373</td>\n",
       "      <td>0.066121</td>\n",
       "      <td>0.439657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n",
       "      <td>0.857491</td>\n",
       "      <td>0.848134</td>\n",
       "      <td>0.058392</td>\n",
       "      <td>0.031194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>0.865356</td>\n",
       "      <td>0.843284</td>\n",
       "      <td>0.065272</td>\n",
       "      <td>0.103137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n",
       "      <td>0.880524</td>\n",
       "      <td>0.842537</td>\n",
       "      <td>0.058338</td>\n",
       "      <td>0.059613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>0.954494</td>\n",
       "      <td>0.840672</td>\n",
       "      <td>0.039434</td>\n",
       "      <td>0.117535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>{'copy_X_train': True, 'kernel': None, 'max_it...</td>\n",
       "      <td>0.916854</td>\n",
       "      <td>0.838806</td>\n",
       "      <td>0.055475</td>\n",
       "      <td>0.22308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NuSVC</td>\n",
       "      <td>{'break_ties': False, 'cache_size': 200, 'clas...</td>\n",
       "      <td>0.854494</td>\n",
       "      <td>0.837313</td>\n",
       "      <td>0.045388</td>\n",
       "      <td>0.076105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.96161</td>\n",
       "      <td>0.833582</td>\n",
       "      <td>0.053027</td>\n",
       "      <td>0.137824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.86573</td>\n",
       "      <td>0.832463</td>\n",
       "      <td>0.036256</td>\n",
       "      <td>0.000599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.96161</td>\n",
       "      <td>0.829104</td>\n",
       "      <td>0.043006</td>\n",
       "      <td>0.126109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.949813</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>0.045608</td>\n",
       "      <td>0.022402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "      <td>0.81779</td>\n",
       "      <td>0.813433</td>\n",
       "      <td>0.070442</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>0.96161</td>\n",
       "      <td>0.812687</td>\n",
       "      <td>0.035681</td>\n",
       "      <td>0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>0.96161</td>\n",
       "      <td>0.805597</td>\n",
       "      <td>0.07827</td>\n",
       "      <td>0.000699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior':...</td>\n",
       "      <td>0.800375</td>\n",
       "      <td>0.798507</td>\n",
       "      <td>0.052025</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'alpha': 0.0001, 'average': False, 'class_wei...</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.797761</td>\n",
       "      <td>0.135794</td>\n",
       "      <td>0.003507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>{'C': 1.0, 'average': False, 'class_weight': N...</td>\n",
       "      <td>0.784082</td>\n",
       "      <td>0.765672</td>\n",
       "      <td>0.374952</td>\n",
       "      <td>0.001712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>{'alpha': 0.0001, 'class_weight': None, 'early...</td>\n",
       "      <td>0.762547</td>\n",
       "      <td>0.751119</td>\n",
       "      <td>0.236565</td>\n",
       "      <td>0.002404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>{'priors': None, 'reg_param': 0.0, 'store_cova...</td>\n",
       "      <td>0.760112</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.090803</td>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA Name  \\\n",
       "19     LinearDiscriminantAnalysis   \n",
       "8               RidgeClassifierCV   \n",
       "3      GradientBoostingClassifier   \n",
       "6            LogisticRegressionCV   \n",
       "16                      LinearSVC   \n",
       "0              AdaBoostClassifier   \n",
       "14                            SVC   \n",
       "21                  XGBClassifier   \n",
       "5       GaussianProcessClassifier   \n",
       "15                          NuSVC   \n",
       "4          RandomForestClassifier   \n",
       "13           KNeighborsClassifier   \n",
       "2            ExtraTreesClassifier   \n",
       "1               BaggingClassifier   \n",
       "12                     GaussianNB   \n",
       "17         DecisionTreeClassifier   \n",
       "18            ExtraTreeClassifier   \n",
       "11                    BernoulliNB   \n",
       "9                   SGDClassifier   \n",
       "7     PassiveAggressiveClassifier   \n",
       "10                     Perceptron   \n",
       "20  QuadraticDiscriminantAnalysis   \n",
       "\n",
       "                                       MLA Parameters MLA Train Accuracy Mean  \\\n",
       "19  {'covariance_estimator': None, 'n_components':...                0.855993   \n",
       "8   {'alphas': array([ 0.1,  1. , 10. ]), 'class_w...                0.855805   \n",
       "3   {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...                0.915543   \n",
       "6   {'Cs': 10, 'class_weight': None, 'cv': None, '...                0.861049   \n",
       "16  {'C': 1.0, 'class_weight': None, 'dual': True,...                0.857491   \n",
       "0   {'algorithm': 'SAMME.R', 'base_estimator': Non...                0.865356   \n",
       "14  {'C': 1.0, 'break_ties': False, 'cache_size': ...                0.880524   \n",
       "21  {'objective': 'binary:logistic', 'use_label_en...                0.954494   \n",
       "5   {'copy_X_train': True, 'kernel': None, 'max_it...                0.916854   \n",
       "15  {'break_ties': False, 'cache_size': 200, 'clas...                0.854494   \n",
       "4   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...                 0.96161   \n",
       "13  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                 0.86573   \n",
       "2   {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...                 0.96161   \n",
       "1   {'base_estimator': None, 'bootstrap': True, 'b...                0.949813   \n",
       "12           {'priors': None, 'var_smoothing': 1e-09}                 0.81779   \n",
       "17  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...                 0.96161   \n",
       "18  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...                 0.96161   \n",
       "11  {'alpha': 1.0, 'binarize': 0.0, 'class_prior':...                0.800375   \n",
       "9   {'alpha': 0.0001, 'average': False, 'class_wei...                0.814607   \n",
       "7   {'C': 1.0, 'average': False, 'class_weight': N...                0.784082   \n",
       "10  {'alpha': 0.0001, 'class_weight': None, 'early...                0.762547   \n",
       "20  {'priors': None, 'reg_param': 0.0, 'store_cova...                0.760112   \n",
       "\n",
       "   MLA Test Accuracy Mean MLA Test Accuracy 3*STD  MLA Time  \n",
       "19               0.853358                0.047241  0.007823  \n",
       "8                0.852985                0.052552  0.009171  \n",
       "3                0.852239                0.060531  0.106151  \n",
       "6                0.850373                0.066121  0.439657  \n",
       "16               0.848134                0.058392  0.031194  \n",
       "0                0.843284                0.065272  0.103137  \n",
       "14               0.842537                0.058338  0.059613  \n",
       "21               0.840672                0.039434  0.117535  \n",
       "5                0.838806                0.055475   0.22308  \n",
       "15               0.837313                0.045388  0.076105  \n",
       "4                0.833582                0.053027  0.137824  \n",
       "13               0.832463                0.036256  0.000599  \n",
       "2                0.829104                0.043006  0.126109  \n",
       "1                0.820896                0.045608  0.022402  \n",
       "12               0.813433                0.070442  0.001002  \n",
       "17               0.812687                0.035681    0.0013  \n",
       "18               0.805597                 0.07827  0.000699  \n",
       "11               0.798507                0.052025    0.0015  \n",
       "9                0.797761                0.135794  0.003507  \n",
       "7                0.765672                0.374952  0.001712  \n",
       "10               0.751119                0.236565  0.002404  \n",
       "20                   0.75                0.090803    0.0021  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Machine Learning Algorithm (MLA) Selection and Initialization\n",
    "MLA = [\n",
    "    #Ensemble Methods\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "\n",
    "    #Gaussian Processes\n",
    "    gaussian_process.GaussianProcessClassifier(),\n",
    "    \n",
    "    #GLM\n",
    "    linear_model.LogisticRegressionCV(),\n",
    "    linear_model.PassiveAggressiveClassifier(),\n",
    "    linear_model.RidgeClassifierCV(),\n",
    "    linear_model.SGDClassifier(),\n",
    "    linear_model.Perceptron(),\n",
    "    \n",
    "    #Navies Bayes\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "    \n",
    "    #Nearest Neighbor\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    \n",
    "    #SVM\n",
    "    svm.SVC(probability=True),\n",
    "    svm.NuSVC(probability=True),\n",
    "    svm.LinearSVC(),\n",
    "    \n",
    "    #Trees    \n",
    "    tree.DecisionTreeClassifier(),\n",
    "    tree.ExtraTreeClassifier(),\n",
    "    \n",
    "    #Discriminant Analysis\n",
    "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "    \n",
    "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "    XGBClassifier()    \n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "#split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
    "#note: this is an alternative to train_test_split\n",
    "cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n",
    "\n",
    "#create table to compare MLA metrics\n",
    "MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "#create table to compare MLA predictions\n",
    "MLA_predict = y_train\n",
    "\n",
    "#index through MLA and save performance to table\n",
    "row_index = 0\n",
    "for alg in MLA:\n",
    "\n",
    "    #set name and parameters\n",
    "    MLA_name = alg.__class__.__name__\n",
    "    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "    \n",
    "    #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "    cv_results = model_selection.cross_validate(alg, X_train, y_train, cv  = cv_split,return_train_score=True)\n",
    "\n",
    "    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n",
    "    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
    "    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n",
    "    #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
    "    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
    "    \n",
    "\n",
    "    #save MLA predictions - see section 6 for usage\n",
    "    alg.fit(X_train, y_train)\n",
    "    \n",
    "    row_index+=1\n",
    "\n",
    "    \n",
    "#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
    "MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
    "MLA_compare\n",
    "#MLA_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLA Name                                                       XGBClassifier\n",
      "MLA Parameters             {'objective': 'binary:logistic', 'use_label_en...\n",
      "MLA Train Accuracy Mean                                             0.954494\n",
      "MLA Test Accuracy Mean                                              0.840672\n",
      "MLA Test Accuracy 3*STD                                             0.039434\n",
      "MLA Time                                                            0.117535\n",
      "Name: 21, dtype: object\n",
      "{'objective': 'binary:logistic', 'use_label_encoder': False, 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': None, 'num_parallel_tree': None, 'predictor': None, 'random_state': None, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "print(MLA_compare.loc[21,:])\n",
    "print(MLA_compare.loc[21,\"MLA Parameters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pick_up_Model = [\n",
    "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "    XGBClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),    \n",
    "    ]\n",
    "i =0\n",
    "cv_split = model_selection.ShuffleSplit(\n",
    "        n_splits=10, test_size=.3, train_size=.6, random_state=0)\n",
    "\n",
    "Model1 = Pick_up_Model[0]\n",
    "cv_results = model_selection.cross_validate(\n",
    "    Model1, X_train, y_train, cv=cv_split, return_train_score=True)\n",
    "Model1.fit(X_train,y_train) \n",
    "Model1_pred = Model1.predict_proba(X_test)\n",
    "\n",
    "Model2 = Pick_up_Model[1]\n",
    "cv_results = model_selection.cross_validate(\n",
    "    Model2, X_train, y_train, cv=cv_split, return_train_score=True)\n",
    "Model2.fit(X_train, y_train)\n",
    "Model2_pred = Model2.predict_proba(X_test)\n",
    "\n",
    "Model3 = Pick_up_Model[2]\n",
    "cv_results = model_selection.cross_validate(\n",
    "    Model3, X_train, y_train, cv=cv_split, return_train_score=True)\n",
    "Model3.fit(X_train, y_train)\n",
    "Model3_pred = Model3.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Model3_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6644/1877048928.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mModel3_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_proba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_proba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Model3_pred' is not defined"
     ]
    }
   ],
   "source": [
    "pred_proba = (Model3_pred)/1\n",
    "type(pred_proba)\n",
    "predict = pred_proba.argmax(axis=1)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission Format:(418, 2) \n",
      "My Sumbisison Format:(418, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_ex = pd.read_csv(\"gender_submission.csv\")\n",
    "submission_df = pd.DataFrame(columns=['PassengerId', Target])\n",
    "submission_df['PassengerId'] = df_test['PassengerId']\n",
    "submission_df.reset_index(drop=True, inplace=True)\n",
    "submission_df[Target] = predict\n",
    "submission_df.to_csv('sub/06_submissions_kaggle.csv', header=True, index=False)\n",
    "print(\"Submission Format:{} \".format(submission_ex.shape))\n",
    "print(\"My Sumbisison Format:{}\".format(submission_df.shape))\n",
    "submission_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission Format:(418, 2) \n",
      "My Sumbisison Format:(418, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Perished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Perished\n",
       "0            892         1\n",
       "1            893         1\n",
       "2            894         1\n",
       "3            895         1\n",
       "4            896         0\n",
       "..           ...       ...\n",
       "413         1305         1\n",
       "414         1306         0\n",
       "415         1307         1\n",
       "416         1308         1\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "submission_ex = pd.read_csv(\"gender_submission.csv\")\n",
    "submission_df = pd.DataFrame(columns=['PassengerId', Target])\n",
    "submission_df['PassengerId'] = df_test['PassengerId']\n",
    "submission_df[Target] = predict\n",
    "submission_df[Final_target] = 0\n",
    "submission_df.loc[submission_df[Target] == 0,Final_target] = 1\n",
    "submission_df.loc[submission_df[Target] == 1, Final_target] = 0\n",
    "submission_df.drop(Target, axis=1, inplace=True)\n",
    "\n",
    "submission_df.reset_index(drop=True, inplace=True)\n",
    "submission_df.to_csv('sub/06_submissions.csv', header=True, index=False)\n",
    "print(\"Submission Format:{} \".format(submission_ex.shape))\n",
    "print(\"My Sumbisison Format:{}\".format(submission_df.shape))\n",
    "submission_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "68ea084522a32e1c5efebe8e26724b4feaefc93bc2807a5a214dcc5b0260bfd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
