{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一言\n",
    "とりあえず全てのモデルの予測足して平均した．\n",
    "## Public Score\n",
    "# 0.766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.2 (tags/v3.9.2:1a79785, Feb 19 2021, 13:44:55) [MSC v.1928 64 bit (AMD64)]\n",
      "pandas version: 1.3.2\n",
      "matplotlib version: 3.4.3\n",
      "NumPy version: 1.22.4\n",
      "SciPy version: 1.7.1\n",
      "IPython version: 7.26.0\n",
      "scikit-learn version: 0.24.2\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "#load packages\n",
    "import sklearn  # collection of machine learning algorithms\n",
    "from IPython import display  # pretty printing of dataframes in Jupyter notebook\n",
    "# collection of functions for scientific computing and advance mathematics\n",
    "import scipy as sp\n",
    "import numpy as np  # foundational package for scientific computing\n",
    "# collection of functions for scientific and publication-ready visualization\n",
    "import matplotlib\n",
    "import pandas as pd  # collection of functions for data processing and analysis modeled after R dataframes with SQL like features\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import feature_selection\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from pandas_profiling import ProfileReport\n",
    "import sweetviz as sv\n",
    "import scipy as sp\n",
    "import string\n",
    "import re as re\n",
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "import time\n",
    "import random\n",
    "import IPython\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import Series, DataFrame\n",
    "import sys  # access to system parameters https://docs.python.org/3/library/sys.html\n",
    "print(\"Python version: {}\". format(sys.version))\n",
    "\n",
    "print(\"pandas version: {}\". format(pd.__version__))\n",
    "\n",
    "print(\"matplotlib version: {}\". format(matplotlib.__version__))\n",
    "\n",
    "print(\"NumPy version: {}\". format(np.__version__))\n",
    "\n",
    "print(\"SciPy version: {}\". format(sp.__version__))\n",
    "\n",
    "print(\"IPython version: {}\". format(IPython.__version__))\n",
    "\n",
    "print(\"scikit-learn version: {}\". format(sklearn.__version__))\n",
    "\n",
    "#misc libraries\n",
    "\n",
    "\n",
    "#ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('-'*25)\n",
    "# データインポートライブラリ\n",
    "\n",
    "# データ加工・処理・分析ライブラリ\n",
    "\n",
    "\n",
    "# 可視化ライブラリ\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#Model\n",
    "%precision 3\n",
    "\n",
    "\n",
    "SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df(train_data, test_data, sort=True, drop=True):\n",
    "    \"\"\"\n",
    "    overview\n",
    "    >return a  concatenated df of training and test data\n",
    "    needed\n",
    "    >pandas as pd\n",
    "    input\n",
    "    >train_data{DataFrame}:train_data\n",
    "    >test_data{DataFrame}:test_data\n",
    "    >sort{bool}:True or False\n",
    "    \"\"\"\n",
    "    return pd.concat([train_data, test_data], sort=sort).reset_index(drop=drop)\n",
    "\n",
    "\n",
    "def divide_df(all_data, target, len=890):\n",
    "    \"\"\"\n",
    "    overview\n",
    "    > Returns divided dfs of training and test set\n",
    "    needed\n",
    "    >\n",
    "    input\n",
    "    > all_data{DataFrame}:Train+Test\n",
    "    > target{str} :Target columns\n",
    "    > len(int):len of train_data\n",
    "    \n",
    "    \"\"\"\n",
    "    return all_data.loc[:len], all_data.loc[len:].drop([target], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 44)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./df/EDA_05_train.csv\")\n",
    "df_test = pd.read_csv(\"./df/EDA_05_test.csv\")\n",
    "Target = 'Survived'\n",
    "Final_target = 'Perished'\n",
    "df_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Deck_1</th>\n",
       "      <th>Deck_2</th>\n",
       "      <th>Deck_3</th>\n",
       "      <th>Deck_4</th>\n",
       "      <th>Embarked_1</th>\n",
       "      <th>Embarked_2</th>\n",
       "      <th>Embarked_3</th>\n",
       "      <th>Family_Size_Grouped_1</th>\n",
       "      <th>Family_Size_Grouped_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_1</th>\n",
       "      <th>Sex_2</th>\n",
       "      <th>Survival_Rate</th>\n",
       "      <th>Survival_Rate_NA</th>\n",
       "      <th>Ticket_Frequency</th>\n",
       "      <th>Title_1</th>\n",
       "      <th>Title_2</th>\n",
       "      <th>Title_3</th>\n",
       "      <th>Title_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Deck_1  Deck_2  Deck_3  Deck_4  Embarked_1  Embarked_2  Embarked_3  \\\n",
       "0    2     0.0     0.0     0.0     1.0         0.0         0.0         1.0   \n",
       "1    7     1.0     0.0     0.0     0.0         1.0         0.0         0.0   \n",
       "2    4     0.0     0.0     0.0     1.0         0.0         0.0         1.0   \n",
       "3    7     1.0     0.0     0.0     0.0         0.0         0.0         1.0   \n",
       "4    7     0.0     0.0     0.0     1.0         0.0         0.0         1.0   \n",
       "\n",
       "   Family_Size_Grouped_1  Family_Size_Grouped_2  ...  Pclass_3  Sex_1  Sex_2  \\\n",
       "0                    0.0                    0.0  ...       1.0    0.0    1.0   \n",
       "1                    0.0                    0.0  ...       0.0    1.0    0.0   \n",
       "2                    1.0                    0.0  ...       1.0    1.0    0.0   \n",
       "3                    0.0                    0.0  ...       0.0    1.0    0.0   \n",
       "4                    1.0                    0.0  ...       1.0    0.0    1.0   \n",
       "\n",
       "   Survival_Rate  Survival_Rate_NA  Ticket_Frequency  Title_1  Title_2  \\\n",
       "0       0.383838               0.0                 1      0.0      0.0   \n",
       "1       1.000000               1.0                 2      0.0      0.0   \n",
       "2       0.383838               0.0                 1      0.0      0.0   \n",
       "3       0.383838               0.0                 2      0.0      0.0   \n",
       "4       0.383838               0.0                 1      0.0      0.0   \n",
       "\n",
       "   Title_3  Title_4  \n",
       "0      0.0      1.0  \n",
       "1      1.0      0.0  \n",
       "2      1.0      0.0  \n",
       "3      1.0      0.0  \n",
       "4      0.0      1.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = concat_df(df_train, df_test)\n",
    "drop_cols = ['Deck', 'Embarked', 'Family', 'Family_Size', 'Family_Size_Grouped', Target,\n",
    "             'Name', 'Parch', 'PassengerId', 'Pclass', 'Sex', 'SibSp', 'Ticket', 'Title',\n",
    "             'Ticket_Survival_Rate', 'Family_Survival_Rate', 'Ticket_Survival_Rate_NA', 'Family_Survival_Rate_NA']\n",
    "\n",
    "df_all.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "df_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (891, 26)\n",
      "y_train shape: (891,)\n",
      "X_test shape: (418, 26)\n"
     ]
    }
   ],
   "source": [
    "X_train = StandardScaler().fit_transform(df_train.drop(columns=drop_cols))\n",
    "y_train = df_train[Target].values\n",
    "X_test = StandardScaler().fit_transform(df_test.drop(columns=drop_cols))\n",
    "print('X_train shape: {}'.format(X_train.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "print('X_test shape: {}'.format(X_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy 3*STD</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>{'covariance_estimator': None, 'n_components':...</td>\n",
       "      <td>0.855993</td>\n",
       "      <td>0.853358</td>\n",
       "      <td>0.047241</td>\n",
       "      <td>0.005063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>0.915543</td>\n",
       "      <td>0.851866</td>\n",
       "      <td>0.061322</td>\n",
       "      <td>0.09723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>{'Cs': 10, 'class_weight': None, 'cv': None, '...</td>\n",
       "      <td>0.861049</td>\n",
       "      <td>0.850373</td>\n",
       "      <td>0.066121</td>\n",
       "      <td>0.460674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n",
       "      <td>0.857303</td>\n",
       "      <td>0.848134</td>\n",
       "      <td>0.058392</td>\n",
       "      <td>0.037232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>0.865356</td>\n",
       "      <td>0.843284</td>\n",
       "      <td>0.065272</td>\n",
       "      <td>0.082403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n",
       "      <td>0.880524</td>\n",
       "      <td>0.842537</td>\n",
       "      <td>0.058338</td>\n",
       "      <td>0.071007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>0.954494</td>\n",
       "      <td>0.840672</td>\n",
       "      <td>0.039434</td>\n",
       "      <td>0.101232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>{'copy_X_train': True, 'kernel': None, 'max_it...</td>\n",
       "      <td>0.916854</td>\n",
       "      <td>0.838806</td>\n",
       "      <td>0.055475</td>\n",
       "      <td>0.219156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NuSVC</td>\n",
       "      <td>{'break_ties': False, 'cache_size': 200, 'clas...</td>\n",
       "      <td>0.854494</td>\n",
       "      <td>0.837313</td>\n",
       "      <td>0.045388</td>\n",
       "      <td>0.081081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.96161</td>\n",
       "      <td>0.834328</td>\n",
       "      <td>0.049101</td>\n",
       "      <td>0.257528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.833209</td>\n",
       "      <td>0.038793</td>\n",
       "      <td>0.000601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.950749</td>\n",
       "      <td>0.829851</td>\n",
       "      <td>0.052073</td>\n",
       "      <td>0.022712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.96161</td>\n",
       "      <td>0.828731</td>\n",
       "      <td>0.043195</td>\n",
       "      <td>0.147246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "      <td>0.81779</td>\n",
       "      <td>0.813433</td>\n",
       "      <td>0.070442</td>\n",
       "      <td>0.001095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>0.96161</td>\n",
       "      <td>0.809328</td>\n",
       "      <td>0.029806</td>\n",
       "      <td>0.001604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior':...</td>\n",
       "      <td>0.800375</td>\n",
       "      <td>0.798507</td>\n",
       "      <td>0.052025</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>0.96161</td>\n",
       "      <td>0.798134</td>\n",
       "      <td>0.049923</td>\n",
       "      <td>0.001057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'alpha': 0.0001, 'average': False, 'class_wei...</td>\n",
       "      <td>0.776592</td>\n",
       "      <td>0.773134</td>\n",
       "      <td>0.268507</td>\n",
       "      <td>0.006454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>{'alpha': 0.0001, 'class_weight': None, 'early...</td>\n",
       "      <td>0.762547</td>\n",
       "      <td>0.751119</td>\n",
       "      <td>0.236565</td>\n",
       "      <td>0.001611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>{'priors': None, 'reg_param': 0.0, 'store_cova...</td>\n",
       "      <td>0.7603</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.090803</td>\n",
       "      <td>0.002483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA Name  \\\n",
       "17     LinearDiscriminantAnalysis   \n",
       "3      GradientBoostingClassifier   \n",
       "6            LogisticRegressionCV   \n",
       "14                      LinearSVC   \n",
       "0              AdaBoostClassifier   \n",
       "12                            SVC   \n",
       "19                  XGBClassifier   \n",
       "5       GaussianProcessClassifier   \n",
       "13                          NuSVC   \n",
       "4          RandomForestClassifier   \n",
       "11           KNeighborsClassifier   \n",
       "1               BaggingClassifier   \n",
       "2            ExtraTreesClassifier   \n",
       "10                     GaussianNB   \n",
       "15         DecisionTreeClassifier   \n",
       "9                     BernoulliNB   \n",
       "16            ExtraTreeClassifier   \n",
       "7                   SGDClassifier   \n",
       "8                      Perceptron   \n",
       "18  QuadraticDiscriminantAnalysis   \n",
       "\n",
       "                                       MLA Parameters MLA Train Accuracy Mean  \\\n",
       "17  {'covariance_estimator': None, 'n_components':...                0.855993   \n",
       "3   {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...                0.915543   \n",
       "6   {'Cs': 10, 'class_weight': None, 'cv': None, '...                0.861049   \n",
       "14  {'C': 1.0, 'class_weight': None, 'dual': True,...                0.857303   \n",
       "0   {'algorithm': 'SAMME.R', 'base_estimator': Non...                0.865356   \n",
       "12  {'C': 1.0, 'break_ties': False, 'cache_size': ...                0.880524   \n",
       "19  {'objective': 'binary:logistic', 'use_label_en...                0.954494   \n",
       "5   {'copy_X_train': True, 'kernel': None, 'max_it...                0.916854   \n",
       "13  {'break_ties': False, 'cache_size': 200, 'clas...                0.854494   \n",
       "4   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...                 0.96161   \n",
       "11  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.865169   \n",
       "1   {'base_estimator': None, 'bootstrap': True, 'b...                0.950749   \n",
       "2   {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...                 0.96161   \n",
       "10           {'priors': None, 'var_smoothing': 1e-09}                 0.81779   \n",
       "15  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...                 0.96161   \n",
       "9   {'alpha': 1.0, 'binarize': 0.0, 'class_prior':...                0.800375   \n",
       "16  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...                 0.96161   \n",
       "7   {'alpha': 0.0001, 'average': False, 'class_wei...                0.776592   \n",
       "8   {'alpha': 0.0001, 'class_weight': None, 'early...                0.762547   \n",
       "18  {'priors': None, 'reg_param': 0.0, 'store_cova...                  0.7603   \n",
       "\n",
       "   MLA Test Accuracy Mean MLA Test Accuracy 3*STD  MLA Time  \n",
       "17               0.853358                0.047241  0.005063  \n",
       "3                0.851866                0.061322   0.09723  \n",
       "6                0.850373                0.066121  0.460674  \n",
       "14               0.848134                0.058392  0.037232  \n",
       "0                0.843284                0.065272  0.082403  \n",
       "12               0.842537                0.058338  0.071007  \n",
       "19               0.840672                0.039434  0.101232  \n",
       "5                0.838806                0.055475  0.219156  \n",
       "13               0.837313                0.045388  0.081081  \n",
       "4                0.834328                0.049101  0.257528  \n",
       "11               0.833209                0.038793  0.000601  \n",
       "1                0.829851                0.052073  0.022712  \n",
       "2                0.828731                0.043195  0.147246  \n",
       "10               0.813433                0.070442  0.001095  \n",
       "15               0.809328                0.029806  0.001604  \n",
       "9                0.798507                0.052025    0.0024  \n",
       "16               0.798134                0.049923  0.001057  \n",
       "7                0.773134                0.268507  0.006454  \n",
       "8                0.751119                0.236565  0.001611  \n",
       "18                   0.75                0.090803  0.002483  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Machine Learning Algorithm (MLA) Selection and Initialization\n",
    "MLA = [\n",
    "    #Ensemble Methods\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "\n",
    "    #Gaussian Processes\n",
    "    gaussian_process.GaussianProcessClassifier(),\n",
    "\n",
    "    #GLM\n",
    "    linear_model.LogisticRegressionCV(),\n",
    "    linear_model.SGDClassifier(),\n",
    "    linear_model.Perceptron(),\n",
    "\n",
    "    #Navies Bayes\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "\n",
    "    #Nearest Neighbor\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "\n",
    "    #SVM\n",
    "    svm.SVC(probability=True),\n",
    "    svm.NuSVC(probability=True),\n",
    "    svm.LinearSVC(),\n",
    "\n",
    "    #Trees\n",
    "    tree.DecisionTreeClassifier(),\n",
    "    tree.ExtraTreeClassifier(),\n",
    "\n",
    "    #Discriminant Analysis\n",
    "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "\n",
    "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "    XGBClassifier()\n",
    "]\n",
    "\n",
    "\n",
    "#split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
    "#note: this is an alternative to train_test_split\n",
    "# run model 10x with 60/30 split intentionally leaving out 10%\n",
    "cv_split = model_selection.ShuffleSplit(\n",
    "    n_splits=10, test_size=.3, train_size=.6, random_state=0)\n",
    "\n",
    "#create table to compare MLA metrics\n",
    "MLA_columns = ['MLA Name', 'MLA Parameters', 'MLA Train Accuracy Mean',\n",
    "               'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD', 'MLA Time']\n",
    "MLA_compare = pd.DataFrame(columns=MLA_columns)\n",
    "\n",
    "#create table to compare MLA predictions\n",
    "MLA_predict = y_train\n",
    "model_list = {}\n",
    "score_list =[]\n",
    "#index through MLA and save performance to table\n",
    "row_index = 0\n",
    "for alg in MLA:\n",
    "\n",
    "    #set name and parameters\n",
    "    MLA_name = alg.__class__.__name__\n",
    "    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "\n",
    "    #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "    cv_results = model_selection.cross_validate(\n",
    "        alg, X_train, y_train, cv=cv_split, return_train_score=True,return_estimator=True)\n",
    "\n",
    "    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n",
    "    MLA_compare.loc[row_index,\n",
    "                    'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
    "    MLA_compare.loc[row_index,\n",
    "                    'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()\n",
    "    #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
    "    # let's know the worst that can happen!\n",
    "    MLA_compare.loc[row_index,\n",
    "                    'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3\n",
    "        \n",
    "    #save MLA predictions - see section 6 for usage\n",
    "    alg.fit(X_train, y_train)\n",
    "    \n",
    "    score_list.append(str(round(cv_results['train_score'].mean(),4)))\n",
    "    try:\n",
    "        model_list[str(round(cv_results['train_score'].mean(),4))]=alg.predict_proba(X_test)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    row_index += 1\n",
    "\n",
    "score_list.sort(reverse=True)\n",
    "#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
    "MLA_compare.sort_values(by=['MLA Test Accuracy Mean'],\n",
    "                        ascending=False, inplace=True)\n",
    "MLA_compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.9616', '0.9616', '0.9616', '0.9616', '0.9545', '0.9507', '0.9169', '0.9155', '0.8805', '0.8654', '0.8652', '0.861', '0.8573', '0.856', '0.8545', '0.8178', '0.8004', '0.7766', '0.7625', '0.7603']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.9616',\n",
       " '0.9616',\n",
       " '0.9616',\n",
       " '0.9616',\n",
       " '0.9545',\n",
       " '0.9507',\n",
       " '0.9169',\n",
       " '0.9155',\n",
       " '0.8805',\n",
       " '0.8654']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(score_list)\n",
    "pick = score_list[:10]\n",
    "pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for i in range(0,len(pick)-1):\n",
    "    if i == 0:\n",
    "        pred = model_list[str(score_list[i])]\n",
    "    else:\n",
    "        try:\n",
    "            pred += model_list[str(score_list[i])]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "predict_prob = (pred/len(model_list))\n",
    "predict= predict_prob.argmax(axis=1)\n",
    "predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission Format:(418, 2) \n",
      "My Sumbisison Format:(418, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Perished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Perished\n",
       "0            892         1\n",
       "1            893         1\n",
       "2            894         1\n",
       "3            895         1\n",
       "4            896         0\n",
       "..           ...       ...\n",
       "413         1305         1\n",
       "414         1306         0\n",
       "415         1307         1\n",
       "416         1308         1\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_ex = pd.read_csv(\"gender_submission.csv\")\n",
    "submission_df = pd.DataFrame(columns=['PassengerId', Target])\n",
    "submission_df['PassengerId'] = df_test['PassengerId']\n",
    "submission_df[Target] = predict\n",
    "submission_df[Final_target] = 0\n",
    "submission_df.loc[submission_df[Target] == 0, Final_target] = 1\n",
    "submission_df.loc[submission_df[Target] == 1, Final_target] = 0\n",
    "submission_df.drop(Target, axis=1, inplace=True)\n",
    "\n",
    "submission_df.reset_index(drop=True, inplace=True)\n",
    "submission_df.to_csv('sub/07_submissions.csv', header=True, index=False)\n",
    "print(\"Submission Format:{} \".format(submission_ex.shape))\n",
    "print(\"My Sumbisison Format:{}\".format(submission_df.shape))\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission Format:(418, 2) \n",
      "My Sumbisison Format:(418, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_ex = pd.read_csv(\"gender_submission.csv\")\n",
    "submission_df = pd.DataFrame(columns=['PassengerId', Target])\n",
    "submission_df['PassengerId'] = df_test['PassengerId']\n",
    "submission_df.reset_index(drop=True, inplace=True)\n",
    "submission_df[Target] = predict\n",
    "submission_df.to_csv('sub/07_submissions_kaggle.csv', header=True, index=False)\n",
    "print(\"Submission Format:{} \".format(submission_ex.shape))\n",
    "print(\"My Sumbisison Format:{}\".format(submission_df.shape))\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "68ea084522a32e1c5efebe8e26724b4feaefc93bc2807a5a214dcc5b0260bfd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
