{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.2 (tags/v3.9.2:1a79785, Feb 19 2021, 13:44:55) [MSC v.1928 64 bit (AMD64)]\n",
      "pandas version: 1.3.2\n",
      "matplotlib version: 3.4.3\n",
      "NumPy version: 1.22.4\n",
      "SciPy version: 1.7.1\n",
      "IPython version: 7.26.0\n",
      "scikit-learn version: 0.24.2\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "import sklearn  # collection of machine learning algorithms\n",
    "from IPython import display  # pretty printing of dataframes in Jupyter notebook\n",
    "# collection of functions for scientific computing and advance mathematics\n",
    "import scipy as sp\n",
    "import numpy as np  # foundational package for scientific computing\n",
    "# collection of functions for scientific and publication-ready visualization\n",
    "import matplotlib\n",
    "import pandas as pd  # collection of functions for data processing and analysis modeled after R dataframes with SQL like features\n",
    "import pandas as pd\n",
    "import sweetviz as sv\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import feature_selection\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from subprocess import check_output\n",
    "import warnings\n",
    "import time\n",
    "import random\n",
    "import IPython\n",
    "import sys  # access to system parameters https://docs.python.org/3/library/sys.html\n",
    "print(\"Python version: {}\". format(sys.version))\n",
    "\n",
    "print(\"pandas version: {}\". format(pd.__version__))\n",
    "\n",
    "print(\"matplotlib version: {}\". format(matplotlib.__version__))\n",
    "\n",
    "print(\"NumPy version: {}\". format(np.__version__))\n",
    "\n",
    "print(\"SciPy version: {}\". format(sp.__version__))\n",
    "\n",
    "print(\"IPython version: {}\". format(IPython.__version__))\n",
    "\n",
    "print(\"scikit-learn version: {}\". format(sklearn.__version__))\n",
    "\n",
    "#misc libraries\n",
    "\n",
    "\n",
    "#ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('-'*25)\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "#misc libraries\n",
    "\n",
    "\n",
    "#Common Model Helpers\n",
    "\n",
    "#Visualization\n",
    "\n",
    "#Configure Visualization Defaults\n",
    "#%matplotlib inline = show plots in Jupyter Notebook browser\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train Data\n",
      "[row :891,column :12]\n",
      "--------------------\n",
      "Shape of Test Data\n",
      "[row :418,column :11]\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#pathからcsvファイルを読み込む場合\n",
    "data_raw = pd.read_csv(\"./data/train.csv\")\n",
    "df_test = pd.read_csv(\"./data/test.csv\")\n",
    "df_train = data_raw.copy(deep=True)\n",
    "data_cleaner = [df_train, df_test]\n",
    "print(\"Shape of Train Data\\n[row :{},column :{}]\".format(\n",
    "    df_train.shape[0], df_train.shape[1]))\n",
    "print(\"--------------------\")\n",
    "print(\"Shape of Test Data\\n[row :{},column :{}]\".format(\n",
    "    df_test.shape[0], df_test.shape[1]))\n",
    "print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in data_cleaner:\n",
    "    #Discrete variables\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "    dataset['IsAlone'] = 1  # initialize to yes/1 is alone\n",
    "    # now update to no/0 if family size is greater than 1\n",
    "    dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0\n",
    "\n",
    "    #quick and dirty code split title from name: http://www.pythonforbeginners.com/dictionary/python-split\n",
    "    dataset['Title'] = dataset['Name'].str.split(\n",
    "        \", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "\n",
    "    #Continuous variable bins; qcut vs cut: https://stackoverflow.com/questions/30211923/what-is-the-difference-between-pandas-qcut-and-pandas-cut\n",
    "    #Fare Bins/Buckets using qcut or frequency bins: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html\n",
    "    dataset['FareBin'] = pd.qcut(dataset['Fare'], 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "for dataset in data_cleaner:\n",
    "    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n",
    "    dataset['Embarked_Code'] = label.fit_transform(dataset['Embarked'])\n",
    "    dataset['Title_Code'] = label.fit_transform(dataset['Title'])\n",
    "    dataset['FareBin_Code'] = label.fit_transform(dataset['FareBin'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Age'][df_train['Title'] == \"Mr\"].fillna(df_train['Age'][df_train['Title'] == \"Mr\"].mean(),inplace=True)\n",
    "df_train['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr\n",
      "Mrs\n",
      "Miss\n",
      "Master\n",
      "Don\n",
      "Rev\n",
      "Dr\n",
      "Mme\n",
      "Ms\n",
      "Major\n",
      "Lady\n",
      "Sir\n",
      "Mlle\n",
      "Col\n",
      "Capt\n",
      "the Countess\n",
      "Jonkheer\n",
      "Mr\n",
      "Mrs\n",
      "Miss\n",
      "Master\n",
      "Ms\n",
      "Col\n",
      "Rev\n",
      "Dr\n",
      "Dona\n"
     ]
    }
   ],
   "source": [
    "dataset = [df_train,df_test]\n",
    "for dataset in data_cleaner:\n",
    "    for i in dataset[\"Title\"].unique():\n",
    "        print(i)\n",
    "        dataset['Age'][dataset['Title'] == i].fillna(dataset['Age'][dataset[\"Title\"] == i].mean(), inplace=True)\n",
    "\n",
    "    # dataset[\"Age\"].fillna(dataset[\"Age\"].mean(),inplace=True)\n",
    "    dataset['AgeBin'] = pd.qcut(dataset['Age'], 3)\n",
    "    dataset['Age_Code'] = label.fit_transform(dataset['AgeBin'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId        0\n",
       "Perished           0\n",
       "Pclass             0\n",
       "Name               0\n",
       "Sex                0\n",
       "Age              177\n",
       "SibSp              0\n",
       "Parch              0\n",
       "Ticket             0\n",
       "Fare               0\n",
       "Cabin            687\n",
       "Embarked           2\n",
       "FamilySize         0\n",
       "IsAlone            0\n",
       "Title              0\n",
       "FareBin            0\n",
       "Sex_Code           0\n",
       "Embarked_Code      0\n",
       "Title_Code         0\n",
       "FareBin_Code       0\n",
       "AgeBin           177\n",
       "Age_Code           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repoort = sv.analyze(df_train,target_feat=\"Perished\")\n",
    "# repoort.show_html(\"SWEETVIZ_REPORT.html\")\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save csv\n",
    "import sys\n",
    "import os\n",
    "PATH_dir = \"./df\"\n",
    "df_train.to_csv(os.path.join(PATH_dir, \"EDA_09_GBDT_train.csv\"), index_label=False)\n",
    "df_test.to_csv(os.path.join(PATH_dir, \"EDA_09_GBDT_test.csv\"), index_label=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "68ea084522a32e1c5efebe8e26724b4feaefc93bc2807a5a214dcc5b0260bfd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
